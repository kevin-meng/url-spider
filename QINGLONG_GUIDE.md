# 青龙面板配置与使用指南（小白保姆级教程）

本文档将手把手教你如何在青龙面板中配置并运行我们刚刚开发的 `url_spider_service` 定时任务。

## 前提条件

1.  **青龙面板已安装并运行**：假设你已经可以通过浏览器访问青龙面板（通常是 `http://你的IP:5700`）。
2.  **Docker 服务已启动**：你的 `url_spider_service` 已经在 Docker 容器中运行（端口 8013）。
    *   *注意：青龙面板本身也是运行在 Docker 里的。如果青龙和我们的服务在同一台机器上，它们可以通过 IP 互相访问；如果在同一个 Docker 网络中，可以通过容器名访问。最简单的方式是用宿主机的真实 IP（如 `192.168.2.18`）。*

---

## 第一步：登录青龙面板

1.  打开浏览器，访问你的青龙面板地址。
2.  输入用户名和密码登录。
3.  如果是首次登录，按照提示初始化即可（选择跳过通知设置，后续再配）。

---

## 第二步：安装依赖（非常重要！）

我们的脚本是用 Python 写的，需要用到一些第三方库（如 `requests` 来调用我们的 API）。青龙面板默认环境可能没有这些库，需要手动添加。

1.  点击左侧菜单栏的 **“依赖管理”**。
2.  点击右上角的 **“新建依赖”** 按钮。
3.  在弹出的窗口中：
    *   **依赖类型**：选择 `Python3`。
    *   **自动拆分**：保持默认（是）。
    *   **名称**：输入以下内容（可以直接复制粘贴）：
        ```text
        requests
        ```
    *   *说明：我们的定时任务脚本其实非常简单，只是发送 HTTP 请求给我们的 `url_spider_service` 服务，所以只需要 `requests` 库。核心逻辑都在服务容器里跑，青龙只负责“按时敲门”。*
4.  点击 **“确定”**。
5.  等待状态变为 **“安装成功”**（日志里显示安装完成）。

---

## 第三步：创建定时任务脚本

我们需要在青龙面板里创建 3 个脚本，分别对应我们的 3 个任务。这些脚本的作用就是**调用我们部署好的 Docker 服务的接口**。

### 1. 创建脚本文件

1.  点击左侧菜单栏的 **“脚本管理”**。
2.  点击右上角的 **“+”** 号（新建）。
3.  **类型**：选择 `空文件`。
4.  **文件名**：输入 `call_spider_task1.py`。
5.  **父目录**：保持默认。
6.  点击 **“确定”**。
7.  在编辑器中，粘贴以下代码：

    ```python
    # 任务 1：获取并评估文章
    # 对应接口：/api/evaluate (实际上我们的服务内部有定时任务逻辑，但为了青龙控制，我们这里调用一个触发接口)
    # 修正：我们的服务设计是内部 Scheduler 跑任务，或者外部脚本跑。
    # 为了青龙控制，我们直接调用服务暴露的 API 接口，或者让青龙执行远程命令。
    # 最简单的方式：我们的服务已经把逻辑封装在 /tasks/ 目录下的脚本里了。
    # 但青龙是在另一个容器。
    # 方案 A：青龙直接发 HTTP 请求给服务（推荐，解耦）。
    # 但我们现在的服务没有暴露“触发任务”的 HTTP 接口，只暴露了核心功能接口。
    # 没关系，我们写一个简单的 Python 脚本，在青龙里运行，去调用服务的核心接口。
    
    # 等等！之前的沟通中，我们已经把任务封装成了独立脚本 task1_fetch.py 等。
    # 这些脚本是在 `url_spider_service` 容器里运行的，依赖了本地数据库连接。
    # 青龙容器里没有数据库环境，也没有 Playwright 浏览器！
    # 所以，青龙不能直接运行 task1_fetch.py。
    
    # 正确的做法是：
    # 1. 在 `url_spider_service` 的 main.py 里增加 3 个 HTTP 接口，专门用来手动触发任务。
    # 2. 青龙脚本只需要 `requests.post` 这 3 个接口即可。
    
    import requests
    import time
    
    # 你的服务地址（宿主机 IP）
    SERVICE_URL = "http://192.168.2.18:8013"
    
    def trigger_task(endpoint_name):
        url = f"{SERVICE_URL}/api/trigger/{endpoint_name}"
        print(f"正在触发任务: {endpoint_name} ...")
        try:
            resp = requests.post(url)
            if resp.status_code == 200:
                print("✅ 触发成功！")
                print(resp.json())
            else:
                print(f"❌ 触发失败: {resp.status_code}")
                print(resp.text)
        except Exception as e:
            print(f"❌ 请求出错: {e}")
            
    if __name__ == "__main__":
        trigger_task("fetch_and_evaluate")
    ```

    **⚠️ 暂停一下！**
    我意识到我们之前的 `main.py` **还没有**提供“触发任务”的 HTTP 接口。
    为了让青龙能控制，我们需要先去修改一下 `url_spider_service` 的代码，增加这 3 个触发接口。
    如果不改代码，青龙就只能当个摆设，或者需要极其复杂的配置（SSH 到容器里执行）。
    **最优雅的方案是：给服务加接口。**

    请允许我先帮您把 `url_spider_service` 更新一下，加上这 3 个接口。

---

### 插播：更新服务代码（增加触发接口）

我将为您修改 `url_spider_service/main.py`，增加 `/api/trigger/fetch_and_evaluate` 等接口。这样青龙只要访问这个网址，任务就开始跑了。

(稍后我会自动执行这个修改，您只需确认即可)

---

### 继续第三步（修改后的流程）

**假设服务代码已经更新好了**，我们继续在青龙里配置。

#### 脚本 1：获取与评估 (`task_fetch.py`)
1.  在“脚本管理”新建 `task_fetch.py`。
2.  内容：
    ```python
    import requests
    print("开始执行：获取与评估任务")
    try:
        # 注意：IP地址要改成你服务器的真实IP
        res = requests.post("http://192.168.2.18:8013/api/trigger/task1")
        print(f"状态码: {res.status_code}")
        print(f"响应: {res.json()}")
    except Exception as e:
        print(f"出错: {e}")
    ```
3.  点击保存。

#### 脚本 2：剪藏内容 (`task_clip.py`)
1.  新建 `task_clip.py`。
2.  内容：
    ```python
    import requests
    print("开始执行：剪藏任务")
    try:
        res = requests.post("http://192.168.2.18:8013/api/trigger/task2")
        print(f"状态码: {res.status_code}")
        print(f"响应: {res.json()}")
    except Exception as e:
        print(f"出错: {e}")
    ```
3.  点击保存。

#### 脚本 3：总结内容 (`task_summarize.py`)
1.  新建 `task_summarize.py`。
2.  内容：
    ```python
    import requests
    print("开始执行：总结任务")
    try:
        res = requests.post("http://192.168.2.18:8013/api/trigger/task3")
        print(f"状态码: {res.status_code}")
        print(f"响应: {res.json()}")
    except Exception as e:
        print(f"出错: {e}")
    ```
3.  点击保存。

---

## 第四步：创建定时任务

现在脚本有了，我们要告诉青龙什么时候跑。

1.  点击左侧菜单栏的 **“定时任务”**。
2.  点击右上角的 **“新建任务”**。

### 任务 1：获取与评估（每30分钟）
*   **名称**：URL爬虫-获取与评估
*   **命令/脚本**：`task task_fetch.py`
*   **定时规则**：`*/30 * * * *`  (意思是每小时的第0和30分钟运行)
*   **标签**：`spider` (可选)

### 任务 2：剪藏内容（每30分钟）
*   **名称**：URL爬虫-剪藏内容
*   **命令/脚本**：`task task_clip.py`
*   **定时规则**：`*/30 * * * *` (意思是每小时的第0和30分钟运行)

### 任务 3：总结内容（每30分钟）
*   **名称**：URL爬虫-总结内容
*   **命令/脚本**：`task task_summarize.py`
*   **定时规则**：`*/30 * * * *` (意思是每小时的第0和30分钟运行)

点击确定保存。

---

## 第五步：测试运行

1.  在“定时任务”列表里，找到刚才创建的任务。
2.  点击右侧的 **“运行”** 按钮（播放图标）。
3.  点击 **“日志”**，查看运行结果。
    *   如果看到 `状态码: 200` 和 `{"status": "triggered", ...}`，说明配置成功！青龙成功指挥了 Docker 服务干活。

---

## 总结

我们做的事情本质是：
1.  **青龙面板**：相当于闹钟。
2.  **Python 脚本**：相当于遥控器。
3.  **Docker 服务**：相当于电视机（干活的主体）。

闹钟响了 -> 触发遥控器 -> 遥控器发信号给电视机 -> 电视机开始播放。

我现在就去帮您**升级电视机（更新服务代码）**，让它支持遥控器信号！

---

## 第六步：添加统计数据计算任务（Task 4）

除了上述三个任务外，我们还需要添加一个统计数据计算任务（Task 4），用于计算每日统计、月度统计和热力图统计。

### 脚本 4：计算统计数据 (`task_stats.py`)
1.  在“脚本管理”新建 `task_stats.py`。
2.  内容：
    ```python
    import requests
    print("开始执行：统计数据计算任务")
    try:
        # 注意：IP地址要改成你服务器的真实IP
        res = requests.post("http://192.168.2.18:8013/api/trigger/task4")
        print(f"状态码: {res.status_code}")
        print(f"响应: {res.json()}")
    except Exception as e:
        print(f"出错: {e}")
    ```
3.  点击保存。

### 任务 4：计算统计数据（每小时）
1.  在“定时任务”列表中，点击右上角的 **“新建任务”**。
2.  配置如下：
    *   **名称**：URL爬虫-计算统计数据
    *   **命令/脚本**：`task task_stats.py`
    *   **定时规则**：`0 * * * *` (意思是每小时的第0分钟运行)
    *   **标签**：`spider` (可选)
3.  点击确定保存。

### 测试运行任务 4
1.  在“定时任务”列表里，找到刚才创建的“URL爬虫-计算统计数据”任务。
2.  点击右侧的 **“运行”** 按钮（播放图标）。
3.  点击 **“日志”**，查看运行结果。
    *   如果看到 `状态码: 200` 和 `{"status": "triggered", ...}`，说明配置成功！青龙成功触发了统计数据计算任务。

---

## 第七步：添加金融调度任务（Task 5）

这个任务用于将高价值（评分8-10分）的文章同步到飞书多维表格，方便进行金融/投资分析和归档。由于它是统计“昨天”的数据，建议每天早上运行一次。

### 脚本 5：金融调度 (`task_financial.py`)
1.  在“脚本管理”新建 `task_financial.py`。
2.  内容：
    ```python
    import requests
    print("开始执行：金融调度任务（同步飞书）")
    try:
        # 注意：IP地址要改成你服务器的真实IP
        res = requests.post("http://192.168.2.18:8013/api/trigger/task5")
        print(f"状态码: {res.status_code}")
        print(f"响应: {res.json()}")
    except Exception as e:
        print(f"出错: {e}")
    ```
3.  点击保存。

### 任务 5：金融调度（每天早上8点）
1.  在“定时任务”列表中，点击右上角的 **“新建任务”**。
2.  配置如下：
    *   **名称**：URL爬虫-金融调度
    *   **命令/脚本**：`task task_financial.py`
    *   **定时规则**：`0 8 * * *` (每天早上8点运行)
    *   **标签**：`spider` (可选)
3.  点击确定保存。

### 测试运行任务 5
1.  在“定时任务”列表里，找到刚才创建的“URL爬虫-金融调度”任务。
2.  点击右侧的 **“运行”** 按钮。
3.  查看日志确认 `状态码: 200`。

---

## 完整任务列表

现在，您的青龙面板中应该有以下 5 个定时任务：

1.  **URL爬虫-获取与评估**：每30分钟运行一次，用于获取并评估文章。
2.  **URL爬虫-剪藏内容**：每30分钟运行一次，用于剪藏文章内容。
3.  **URL爬虫-总结内容**：每30分钟运行一次，用于总结文章内容。
4.  **URL爬虫-计算统计数据**：每小时运行一次，用于计算统计数据。
5.  **URL爬虫-金融调度**：每天早上8点运行一次，用于同步高价值文章到飞书。

这些任务将协同工作，确保您的微信公众号数据监控系统能够正常运行，为您提供全面的数据分析和可视化。
